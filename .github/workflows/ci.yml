name: CI
on:
  push: { branches: [ TwinLiteNet ] }
  pull_request: { branches: [ TwinLiteNet ] }

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: ${{ github.workspace }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies (CPU wheels)
        run: |
          python -m pip install --upgrade pip
          pip install --extra-index-url https://download.pytorch.org/whl/cpu \
            torch==2.3.* torchvision==0.18.* torchaudio==2.3.*
          pip install pytest numpy pillow opencv-python-headless albumentations

      - name: Run tests
        run: pytest -q --maxfail=1 --disable-warnings

      # opcional: exporta um ONNX do modelo 'nano' e guarda como artifact
      - name: Export ONNX (nano)
        run: |
          python - <<'PY'
          import torch, os
          from linenet import create_linenet
          m = create_linenet('nano', 1).eval()
          x = torch.randn(1, 3, 96, 96)
          os.makedirs('build', exist_ok=True)
          torch.onnx.export(
              m, x, 'build/linenet_nano.onnx',
              input_names=['input'], output_names=['mask'],
              opset_version=11,
              dynamic_axes={'input': {0: 'batch'}, 'mask': {0: 'batch'}}
          )
          print('Exported to build/linenet_nano.onnx')
          PY
      - name: Upload ONNX artifact
        uses: actions/upload-artifact@v4
        with:
          name: onnx
          path: build/linenet_nano.onnx
